#' Estimate the model parameters
#'
#'
#' This is an interface function to estimate the model parameters 
#' based on the task-level (i.e., passage-level in ORF assessment 
#' context) accuracy and speed data by implementing 
#' the Monte Carlo EM algorithm described in Potgieter et al. (2017) or
#' fully Bayesian method described in Kara et al. (2020).
#'
#'
#' @param data A data frame. A wide-format response data 
#'     generated by the \code{prep} function. If this argument is used, 
#'     the next 6 arguments \code{person.data, person.id, task.id, 
#'     max.counts, obs.counts, time} should be skipped.
#' @param person.data A data frame. A long-format response 
#'     data object. If this this argument is used, the previous argument 
#'     \code{data} should be skipped.
#' @param person.id Quoted variable name in \code{person.data} that indicates 
#'     the unique person identifier.
#' @param task.id Quoted variable name in \code{person.data} that indicates 
#'     the unique task identifier. In the ORF assessment context, it is the
#'     passage identifier.
#' @param max.counts Quoted variable name in \code{person.data} that indicates 
#'     the number of attempts in the task. In the ORF assessment context,
#'     it is the number of words in the passage. 
#' @param obs.counts Quoted variable name in \code{person.data} that indicates 
#'     the number of successful attempts in each task. In the ORF assessment
#'     context, it is the number of words read correctly for the passage.
#' @param time Quoted variable name in \code{person.data} that indicates 
#'     the time in seconds took to complete the task. In the ORF context, 
#'     it is the time took to complete reading the passage.
#' @param k.in    Numeric, indicating the number of imputations. 
#'     Default is \code{5}.
#' @param reps.in Numeric, indicating the number of Monte-Carlo iterations. 
#'     Default is \code{2}.
#' @param ests.in An optional list of numeric vectors, indicating 
#'     initial values of the model parameters. If this argument is not given, 
#'     \code{mom} function will be called to generate the initial values.
#' @param est Quoted string, indicating the choice of the estimator. It has
#'     to be one of \code{"mcem", "bayes"}. Default is \code{"mcem"}.
#' @param se Quoted string, indicating the choice of the standard errors. 
#'     It has to be one of \code{"none", "analytic", "bootstrap"}. 
#'     Default is \code{"none"}.
#' @param verbose Boolean. If \code{TRUE}, the summary will be output.
#'     Default is \code{FALSE}.
#'
#' @details
#' Additional details...
#' 
#' @note
#' More & more additional note...
#' 
#' @seealso \code{\link{scoring}} for scoring.
#'
#' @references 
#'   Potgieter, N., Kamata, A., & Kara, Y. (2017). An EM algorithm for 
#'   estimating an oral reading speed and accuracy model. Manuscript submitted 
#'   for publication.  
#'   
#'   Kara, Y., Kamata, A., Potgieter, C., & Nese, J. F. (2020). Estimating 
#'   model-based oral reading fluency: A bayesian approach with a 
#'   binomial-lognormal joint latent model. 
#'   Educational and Psychological Measurement, 1â€“25.
#'   
#' @examples
#' # example code
#' MCEM_run <- fit.model(person.data = passage2,
#'                       person.id = "id.student",
#'                       task.id = "id.passage",
#'                       max.counts = "numwords.pass",
#'                       obs.counts = "wrc",
#'                       time = "sec",
#'                       k.in = 5,
#'                       reps.in = 50,
#'                       est = "mcem")
#' 
#' @return MCEM list, bayes list
#' @export
fit.model <- function(data=NA, person.data=NA, person.id="",task.id="",max.counts="",obs.counts="",time="", k.in=5,reps.in=2,ests.in=NA,
                      est="mcem",se="none",verbose=FALSE) {
  # loading logger
  log.initiating()

  if (person.id != "") {
    #create wide data
    data <- prepwide(person.data,person.id,task.id,max.counts,obs.counts,time)
  }

  if (est == "mcem") {
    flog.info("Begin mcem process", name = "orfrlog")
    
    if (se == "none") {

      MCEMests <- run.mcem(data$Y,data$logT10,data$N,data$I,k.in,reps.in,ests.in,verbose=verbose)

      task.param <-  tibble(
        a = MCEMests$a,
        b = MCEMests$b,
        alpha = MCEMests$alpha,
        beta = MCEMests$beta,
        task.id = as.numeric(colnames(data$Y)),
        max.counts = data$N)
      hyper.param <- tibble(vartau = MCEMests$vartau,
                            rho = MCEMests$rho)
      MCEM.ests <- list(task.param = task.param,
                        hyper.param = hyper.param)
    } else {
      # test
      # if (is.na(ests.in)) {
      #   ests.in <- mom(data$Y, data$logT10, data$N, data$I)
      # }

      MCEMests <- run.mcem(data$Y, data$logT10, data$N, data$I,
                           k.in=k.in, reps.in=reps.in,ests.in=ests.in)

      MCEMout <- c(MCEMests$a, MCEMests$b, MCEMests$alpha,
                   MCEMests$beta, MCEMests$vartau, MCEMests$rho)
      if (se == "analytic") {
        CV.analytic <- numerical.cov(data$Y, data$logT10, data$N, data$I,
                                     MCEMout,h.val=1e-10, M=100)
      } else { # bootstrap
        # CV.analytic <- boot.cov(data$Y, data$logT10, data$N, data$I,
        #                         k.in=8, reps.in=3, B=10)
        # an alternative function
        CV.analytic <- bootmodel.cov(data$Y, data$logT10, data$N, data$I,
                                     MCEMout,k.in=k.in, reps.in=reps.in,B=10)

      }
      SE.analytic <- sqrt(diag(CV.analytic))

      task.param <-  tibble(
        a = MCEMests$a,
        b = MCEMests$b,
        alpha = MCEMests$alpha,
        beta = MCEMests$beta,
        se.a = SE.analytic[1:length(MCEMests$a)],
        se.b = SE.analytic[(length(MCEMests$a)+1):(length(MCEMests$a)+length(MCEMests$b))],
        se.alpha = SE.analytic[(length(MCEMests$a)+length(MCEMests$b)+1):(length(MCEMests$a)+length(MCEMests$b)+length(MCEMests$alpha))],
        se.beta = SE.analytic[(length(MCEMests$a)+length(MCEMests$b)+length(MCEMests$alpha)+1):(length(MCEMests$a)+length(MCEMests$b)+length(MCEMests$alpha)+length(MCEMests$beta))],
        task.id = as.numeric(colnames(data$Y)),
        max.counts = data$N)
      hyper.param <- tibble(vartau = MCEMests$vartau,
                            rho = MCEMests$rho,
                            se.vartau = SE.analytic[(length(MCEMests$a)+length(MCEMests$b)+length(MCEMests$alpha)+length(MCEMests$beta)+1)],
                            se.rho = SE.analytic[(length(MCEMests$a)+length(MCEMests$b)+length(MCEMests$alpha)+length(MCEMests$beta)+2)])
      MCEM.ests <- list(task.param = task.param,
                        hyper.param = hyper.param)
    }


    # check if shows the summary
    if (verbose == TRUE) {
      summary.fit.model(MCEM.ests)
    }
    class(MCEM.ests) <- "fit.model" # define class
    flog.info("End mcem process", name = "orfrlog")
    return(invisible(MCEM.ests))


  } else { # for bayes, mcem parameters are necessary
    flog.info("Begin bayes process", name = "orfrlog")
    bayes.ests <- bayes(person.data,
                       person.id,
                       task.id,
                       max.counts,
                       obs.counts,
                       time,
                       parallel=T, #logical, run in parallel? "T" or "F"
                       n.chains=NA, # pos. int., number of the chains
                       thin=1, #pos. int, thinning interval, a.k.a, period of saving samples
                       iter=NA,  # pos. int., number of the iterations after the burn-in period
                       burn=NA  # pos. int., number of the burn-in iterations)
    )
    # check if shows the summary
    if (verbose == TRUE) {
      summary.fit.model(bayes.ests)
    }

    class(bayes.ests) <- "fit.model" # define class
    flog.info("End bayes process", name = "orfrlog")
    return(invisible(bayes.ests))
  }
}

#' Estimate factor scores with task-level model
#'
#' This is an interface function to estimated factor scores based on the 
#' task-level (i.e., passage-level in ORF assessment context) accuracy 
#' and speed data. It implements likelihood-based approaches (MLE, MAP,
#' or EAP) described in Qiao et al. (under review) or fully Bayesian 
#' method described in Kara et al. (2020).
#' 
#'
#' @param calib.data A class object. Output from calibration phase 
#'     by \code{\link{fit.model}} function
#' @param person.data A data frame. A long-format response data object. 
#' @param person.id Quoted variable name in \code{person.data} that 
#'     indicates the unique individual identifier.
#' @param task.id Quoted variable name in \code{person.data} that 
#'     represents the unique task identifier. In the ORF assessment
#'     context, it is the passage identifier.
#' @param max.counts Quoted variable name in \code{person.data} that 
#'     represents the number of attempts in the task. In the ORF assessment
#'     context, it is the number of words in the passage.
#' @param occasion The column name in the data that represents the unique occasion.
#' @param group The column name in the data that represents the unique group.
#' @param obs.counts The column name in the data that represents the words read correctly for each case.
#' @param time The column name in the data that represents the time, in seconds, for each case.
#' @param cases - individual id vectors, will directly use task data if no calib.data provided
#' @param est - estimator keyword / c("mle", "map", "eap", "bayes"), default is bayes
#' @param se - standard error keyword / c("analytic", "bootstrap"), default is analytic
#' @param failsafe - retry time for bootstrap / default 0, can set to 5 ~ 50
#' @param bootstrp - set K number of bootstrap / default 100
#' @param external - if not NULL, will use not student read passages for estimating
#' @param type - output type, "general" and "orf", default "general" only output tau & theta. "orf" will output wcpm
#'
#' @details
#' Additional details...
#' 
#' @note
#' More & more additional note...
#' 
#' @seealso \code{\link{fit.model}} for model parameter estimation.
#'
#' @references 
#'   Qiao, X, Potgieter, N., & Kamata, A. (2023). Likelihood Estimation of 
#'   Model-based Oral Reading Fluency. Manuscript submitted 
#'   for publication.  
#'   
#'   Kara, Y., Kamata, A., Potgieter, C., & Nese, J. F. (2020). Estimating 
#'   model-based oral reading fluency: A bayesian approach with a 
#'   binomial-lognormal joint latent model. 
#'   Educational and Psychological Measurement, 1â€“25.
#'   
#' @examples
#' # example code
#' WCPM_all <- scoring(calib.data=MCEM_run, 
#'                    person.data = passage2,
#'                    person.id = "id.student",
#'                    occasion = "occasion",
#'                    group = "grade",
#'                    task.id = "id.passage",
#'                    max.counts = "numwords.pass",
#'                    obs.counts = "wrc",
#'                    time = "sec",
#'                    est = "map", 
#'                    se = "analytic",
#'                    type="general")
#' 
#' @return scoring list or Bootstrap dataset
#' @export
scoring <- function(calib.data=NA, person.data=NA, person.id="",task.id="",occasion="",group="",max.counts="",obs.counts="",time="", cases=NULL,
                    est="map", se="analytic",failsafe=0, bootstrap=100, external=NULL, type="general") {
  # loading logger
  log.initiating()

  bootstrap.out <- tibble()
  error_case <- tibble()
  if (se == "analytic") {
    if (est != "bayes") { #not bayes
      if (person.id != "") {
        person.data <- preplong(person.data,person.id,task.id,occasion,group,max.counts,obs.counts,time)
      }
      # Check MCEM object
      if (class(calib.data)[1] == "fit.model") {
        #      MCEM <- calib.data
        # assign task.data
        task.data <- calib.data$task.param
      } else { # if no MCEM object stop running
        flog.info("Missed fit.model object, end scoring process", name = "orfrlog")
        return(NULL)
      }

      if (length(external) != 0) { # external,
        print(paste("Use external task:", paste(external, collapse = ",")))
      }

      # Check cases
      if (length(cases) == 0) {
        # print("Cases: ")
        cases <- get.cases(person.data)
      } else { # check if cases is with "_"
        colnames(cases) <- c("cases")
        if (!grepl("_", cases[1,1], fixed = TRUE)) { # if task.id only
          cases <- cases %>% mutate(across(cases, ~ paste0(.,'_1')))
        } 
      }
      
      # Check if there is a perfect accurate case
      perfect.cases <<- get.perfectcases(person.data)

      if (count(perfect.cases) != 0) {
        flog.info(paste("The perfect accurate case: ", paste(perfect.cases$perfect.cases, collapse = ", ")), name="orfrlog")
      } else {
        flog.info("There is no perfect accurate case.", name="orfrlog")
      }

      result.list <- run.scoring(calib.data, person.data, task.data, cases, perfect.cases, est, lo = -4, hi = 4, q = 100, kappa = 1, external=external,type=type)
    } else  { # bayes
      if (person.id == "") { # if without columns' names
        result.list <- bayes.wcpm(
          calib.data = calib.data,
          person.data = person.data,
          cases = cases,
          external=external,
          type=type,
          parallel=T, #logical, run in parallel? "T" or "F"
          n.chains=NA, # pos. int., number of the chains
          iter=NA,  # pos. int., number of the iterations after the burn-in period
          burn=NA,  # pos. int., number of the burn-in iterations
          thin=1 #pos. int, thinning interval, a.k.a, period of saving samples
        )
      } else {
        result.list <- bayes.wcpm(
          calib.data = calib.data,
          person.data = person.data,
          person.id = person.id,
          task.id = task.id,
          occasion = occasion,
          group = group,
          max.counts = max.counts,
          obs.counts = obs.counts,
          time = time,
          cases = cases,
          external=external,
          type=type,
          parallel=T, #logical, run in parallel? "T" or "F"
          n.chains=NA, # pos. int., number of the chains
          iter=NA,  # pos. int., number of the iterations after the burn-in period
          burn=NA,  # pos. int., number of the burn-in iterations
          thin=1 #pos. int, thinning interval, a.k.a, period of saving samples
        )
      }
      class(result.list) <- "scoring"
      return(result.list)
    }
  } else if (se == "bootstrap"){ #for bootstrap
    # Check if there is a perfect accurate case
    perfect.cases <<- get.perfectcases(person.data)

    RE_TRY <- failsafe # Define retry, if 0, no retry
    j <- 0 # index for retry time
    i <- 1 # index for case loop

    t_size <- nrow(cases)

    while (i <= t_size) {
      temp <- tibble()
      flog.info(paste("Boostrap running for case:", cases$cases[i]), name = "orfrlog")
      t_case = data.frame(cases=cases$cases[i])
      tryCatchLog(
        temp <- getBootstrapSE(calib.data, person.data, case=t_case, perfect.cases, est, kappa=1,bootstrap=bootstrap),
        error=function(e) {
          flog.info(paste("Running error:", e), name = "orfrlog")
        }
      )

      if (length(temp) > 2) { #without error
        bootstrap.out <- rbind(bootstrap.out,temp)
        j <- 0 # reset index of retry
        i <- i + 1 # go to next case
      } else { # with error
        if (j == RE_TRY) { # after RE_TRY if still error
          error_temp <- tibble(case_id = cases$cases[i])
          error_case <- rbind(error_case, error_temp)
          i <- i + 1 # go to next case
        } else {
          # let it retry a couple of times
          j <- j + 1
          flog.info(paste("Boostrap try again: time", j), name = "orfrlog")
        }
      }
    }
    result.list <- list(bootstrap.out = bootstrap.out,
                        error_case = error_case)
    class(result.list) <- "bootstrap"
    return(result.list)
  }
}
