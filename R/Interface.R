#' Estimate the model parameters
#'
#'
#' This is an interface function to estimate the model parameters 
#' based on the task-level (i.e., passage-level in ORF assessment 
#' context) accuracy and speed data by implementing 
#' the Monte Carlo EM algorithm described in Potgieter et al. (2017) or
#' fully Bayesian method described in Kara et al. (2020).
#'
#'
#' @param data A data frame or a data generated by the \code{prep} function. 
#'     If this argument is used with prepared data, 
#'     the next five arguments \code{person.id, task.id, 
#'     max.counts, obs.counts, time} should be skipped.
#' @param person.id Quoted variable name in \code{data} that indicates 
#'     the unique person identifier.
#' @param task.id Quoted variable name in \code{data} that indicates 
#'     the unique task identifier. In the ORF assessment context, it is the
#'     passage identifier.
#' @param sub.task.id Quoted variable name in \code{data} that indicates 
#'     the unique sub task identifier. In the ORF assessment context, it is the
#'     sentence identifier. It is required when testlet is TRUE.
#' @param max.counts Quoted variable name in \code{data} that indicates 
#'     the number of attempts in the task. In the ORF assessment context,
#'     it is the number of words in the passage. 
#' @param obs.counts Quoted variable name in \code{data} that indicates 
#'     the number of successful attempts in each task. In the ORF assessment
#'     context, it is the number of words read correctly for the passage.
#' @param time Quoted variable name in \code{data} that indicates 
#'     the time in seconds took to complete the task. In the ORF context, 
#'     it is the time took to complete reading the passage.
#' @param k.in    Numeric, indicating the number of imputations. 
#'     Default is \code{5}.
#' @param reps.in Numeric, indicating the number of Monte-Carlo iterations. 
#'     Default is \code{2}.
#' @param ests.in An optional list of numeric vectors, indicating 
#'     initial values of the model parameters. If this argument is not given, 
#'     \code{mom} function will be called to generate the initial values.
#' @param est Quoted string, indicating the choice of the estimator. It has
#'     to be one of \code{"mcem", "bayes"}. Default is \code{"mcem"}.
#' @param se Quoted string, indicating the choice of the standard errors. 
#'     It has to be one of \code{"none", "analytic", "bootstrap"}. 
#'     Default is \code{"none"}.
#' @param verbose Boolean. If \code{TRUE}, the summary will be output.
#'     Default is \code{FALSE}.
#' @param testlet Boolean. If \code{TRUE}, the fit.model.testlet will be run.
#'     Default is \code{FALSE}.
#'
#' @details
#' Additional details...
#' 
#' @note
#' More & more additional note...
#' 
#' @seealso \code{\link{scoring}} for scoring.
#'
#' @references 
#'   Potgieter, N., Kamata, A., & Kara, Y. (2017). An EM algorithm for 
#'   estimating an oral reading speed and accuracy model. Manuscript submitted 
#'   for publication.  
#'   
#'   Kara, Y., Kamata, A., Potgieter, C., & Nese, J. F. (2020). Estimating 
#'   model-based oral reading fluency: A bayesian approach with a 
#'   binomial-lognormal joint latent model. 
#'   Educational and Psychological Measurement, 1â€“25.
#'   
#' @examples
#' # example code
#' MCEM_run <- fit.model(data = passage2,
#'                       person.id = "id.student",
#'                       task.id = "id.passage",
#'                       max.counts = "numwords.pass",
#'                       obs.counts = "wrc",
#'                       time = "sec",
#'                       k.in = 5,
#'                       reps.in = 50,
#'                       est = "mcem")
#' 
#' @return MCEM list, bayes list
#' @export
fit.model <- function(data=NA, person.id="",task.id="",sub.task.id="",max.counts="",obs.counts="",time="", k.in=5,reps.in=2,ests.in=NA,
                      est="mcem",se="none",verbose=FALSE, testlet=FALSE) {
  # loading logger
  log.initiating()

  if (person.id != "") {
    if (testlet) { # for sub task level 

      # call fit.model.testlet
      output <- fit.model.testlet(data,person.id,sub.task.id,obs.counts,time,task.id,max.counts)
      if (verbose == TRUE) {
        summary.fit.model.testlet(output)
      }
      return(invisible(output))
    } else { # task level 
      #create wide data
      if (est != "bayes") {
        data <- prepwide(data,person.id,task.id,max.counts,obs.counts,time)       
      }
    }
  } else { # prepared data
    if (testlet) { # for sub task level 
      output <- fit.model.testlet(data$data.long,person.id="person.id",sub.task.id="sub.task.id",obs.counts="obs.counts",time="time",task.id="task.id",max.counts="max.counts")
      if (verbose == TRUE) {
        summary.fit.model.testlet(output)
      }
      return(invisible(output))
    } else {
      data <- data$data.wide      
    }
  }
  

  if (est == "mcem") {
    flog.info("Begin mcem process", name = "orfrlog")
    
    if (se == "none") {

      MCEMests <- run.mcem(data$Y,data$logT10,data$N,data$I,k.in,reps.in,ests.in,verbose=verbose)

      task.param <-  tibble(
        a = MCEMests$a,
        b = MCEMests$b,
        alpha = MCEMests$alpha,
        beta = MCEMests$beta,
        task.id = as.numeric(colnames(data$Y)),
        max.counts = data$N)
      hyper.param <- tibble(vartau = MCEMests$vartau,
                            rho = MCEMests$rho)
      MCEM.ests <- list(task.param = task.param,
                        hyper.param = hyper.param)
    } else {
      # test
      # if (is.na(ests.in)) {
      #   ests.in <- mom(data$Y, data$logT10, data$N, data$I)
      # }

      MCEMests <- run.mcem(data$Y, data$logT10, data$N, data$I,
                           k.in=k.in, reps.in=reps.in,ests.in=ests.in)

      MCEMout <- c(MCEMests$a, MCEMests$b, MCEMests$alpha,
                   MCEMests$beta, MCEMests$vartau, MCEMests$rho)
      if (se == "analytic") {
        CV.analytic <- numerical.cov(data$Y, data$logT10, data$N, data$I,
                                     MCEMout,h.val=1e-10, M=100)
      } else { # bootstrap
        # CV.analytic <- boot.cov(data$Y, data$logT10, data$N, data$I,
        #                         k.in=8, reps.in=3, B=10)
        # an alternative function
        CV.analytic <- bootmodel.cov(data$Y, data$logT10, data$N, data$I,
                                     MCEMout,k.in=k.in, reps.in=reps.in,B=10)

      }
      SE.analytic <- sqrt(diag(CV.analytic))

      task.param <-  tibble(
        a = MCEMests$a,
        b = MCEMests$b,
        alpha = MCEMests$alpha,
        beta = MCEMests$beta,
        se.a = SE.analytic[1:length(MCEMests$a)],
        se.b = SE.analytic[(length(MCEMests$a)+1):(length(MCEMests$a)+length(MCEMests$b))],
        se.alpha = SE.analytic[(length(MCEMests$a)+length(MCEMests$b)+1):(length(MCEMests$a)+length(MCEMests$b)+length(MCEMests$alpha))],
        se.beta = SE.analytic[(length(MCEMests$a)+length(MCEMests$b)+length(MCEMests$alpha)+1):(length(MCEMests$a)+length(MCEMests$b)+length(MCEMests$alpha)+length(MCEMests$beta))],
        task.id = as.numeric(colnames(data$Y)),
        max.counts = data$N)
      hyper.param <- tibble(vartau = MCEMests$vartau,
                            rho = MCEMests$rho,
                            se.vartau = SE.analytic[(length(MCEMests$a)+length(MCEMests$b)+length(MCEMests$alpha)+length(MCEMests$beta)+1)],
                            se.rho = SE.analytic[(length(MCEMests$a)+length(MCEMests$b)+length(MCEMests$alpha)+length(MCEMests$beta)+2)])
      MCEM.ests <- list(task.param = task.param,
                        hyper.param = hyper.param)
    }


    # check if shows the summary
    if (verbose == TRUE) {
      summary.fit.model(MCEM.ests)
    }
    class(MCEM.ests) <- "fit.model" # define class
    flog.info("End mcem process", name = "orfrlog")
    return(invisible(MCEM.ests))


  } else { # for bayes, mcem parameters are necessary
    flog.info("Begin bayes process", name = "orfrlog")
    bayes.ests <- bayes(data,
                       person.id,
                       task.id,
                       max.counts,
                       obs.counts,
                       time,
                       parallel=T, #logical, run in parallel? "T" or "F"
                       n.chains=NA, # pos. int., number of the chains
                       thin=1, #pos. int, thinning interval, a.k.a, period of saving samples
                       iter=NA,  # pos. int., number of the iterations after the burn-in period
                       burn=NA  # pos. int., number of the burn-in iterations)
    )
    # check if shows the summary
    if (verbose == TRUE) {
      summary.fit.model(bayes.ests)
    }

    class(bayes.ests) <- "fit.model" # define class
    flog.info("End bayes process", name = "orfrlog")
    return(invisible(bayes.ests))
  }
}

#' Estimate factor scores with task-level model
#'
#' This is an interface function to estimated factor scores based on the 
#' task-level (i.e., passage-level in ORF assessment context) accuracy 
#' and speed data. It implements likelihood-based approaches (MLE, MAP,
#' or EAP) described in Qiao et al. (under review) or fully Bayesian 
#' method described in Kara et al. (2020).
#' 
#'
#' @param calib.data A class object. Output from calibration phase 
#'     by \code{\link{fit.model}} function
#' @param data A data frame. It is necessary when with 
#'      the next five arguments \code{person.id, task.id, 
#'     max. counts, obs. counts, time}.
#' @param person.id Quoted variable name in \code{data} that 
#'     indicates the unique individual identifier.
#' @param task.id Quoted variable name in \code{data} that 
#'     represents the unique task identifier. In the ORF assessment
#'     context, it is the passage identifier.
#' @param sub.task.id Quoted variable name in \code{data} that indicates 
#'     the unique sub task identifier. In the ORF assessment context, it is the
#'     sentence identifier. It is required when testlet is TRUE.
#' @param max.counts Quoted variable name in \code{data} that 
#'     represents the number of attempts in the task. In the ORF assessment
#'     context, it is the number of words in the passage.
#' @param occasion The column name in the data that represents the unique occasion.
#' @param group The column name in the data that represents the unique group.
#' @param obs.counts The column name in the data that represents the words read correctly for each case.
#' @param time The column name in the data that represents the time, in seconds, for each case.
#' @param cens The column name in the data that represents the censoring indicators 
#'      whether a specific task or sub task was censored (1) or fully observed (0).
#'      This column is necessary when censoring argument is TRUE.
#' @param cases A vector of individual id for which scoring is desired. If no information is 
#'      is specified, it will estimate scores for all cases in the \code{data}.
#' @param est Quoted string, indicating the choice of the estimator. It has to be one of 
#'      code/{"mle", "map", "eap", "bayes"}. Default is \code{"map"}.
#' @param se Quoted string, indication the choice of the standard errors. It has to be one of
#'      code/{"analytic", "bootstrap"}. Default is \code{"analytic"}.
#' @param failsafe Numeric, indicating the number of retries for bootstrap, which can be set between
#'      0 and 50. Default is 0.
#' @param bootstrp Numeric, indicating the number of bootstrap iterations. Default is 100.
#' @param external An optional vector of task ID's in strings. If \code{NULL} (default), 
#'      the wcpm scores are derived with the tasks the individuals were assigned to. 
#'      If not \code{NULL}, wcpm scores are derived with the tasks provided in the vector, rather
#'      than the tasks the individuals were assigned.
#' @param type Quoted string, indication of the choice of output. If \code{"general"} (default),
#'      wcpm scores are not reported. If \code{"orf"}, wcpm scores will be reported.
#' @param censoring Boolean. If \code{TRUE}, interface will call task or sub task censoring.
#'      Default is \code{FALSE}.
#' @param testlet Boolean. If \code{TRUE}, runs with sub task level, otherwise, with task level.
#'      This argument is necessary when censoring is TRUE. Default is \code{FALSE}.
#'
#' @details
#' Additional details...
#' 
#' @note
#' More additional note...
#' 
#' @seealso \code{\link{fit.model}} for model parameter estimation.
#'
#' @references 
#'   Qiao, X, Potgieter, N., & Kamata, A. (2023). Likelihood Estimation of 
#'   Model-based Oral Reading Fluency. Manuscript submitted 
#'   for publication.  
#'   
#'   Kara, Y., Kamata, A., Potgieter, C., & Nese, J. F. (2020). Estimating 
#'   model-based oral reading fluency: A bayesian approach with a 
#'   binomial-lognormal joint latent model. 
#'   Educational and Psychological Measurement, 1â€“25.
#'   
#' @examples
#' # example code
#' WCPM_all <- scoring(calib.data=MCEM_run, 
#'                    data = passage2,
#'                    person.id = "id.student",
#'                    occasion = "occasion",
#'                    group = "grade",
#'                    task.id = "id.passage",
#'                    max.counts = "numwords.pass",
#'                    obs.counts = "wrc",
#'                    time = "sec",
#'                    est = "map", 
#'                    se = "analytic",
#'                    type="general")
#' 
#' @return scoring list or Bootstrap dataset or censoring list
#' @export
scoring <- function(calib.data=NA, data=NA, person.id="", task.id="", sub.task.id="", occasion="", group="", max.counts="", obs.counts="", time="", cens="", cases=NULL,
                    est="map", se="analytic",failsafe=0, bootstrap=100, external=NULL, type="general", censoring=FALSE, testlet=FALSE) {
  # loading logger
  log.initiating()
  
  bootstrap.out <- tibble()
  error_case <- tibble()
  prep_data <- NULL
  
  # with censoring
  if (censoring) { # when censoring
    if (person.id != "") {
      if (testlet) {
        prep_data <- prep(data,person.id,task.id,occasion,group,max.counts,obs.counts,time, cens,sentence_level = TRUE)
      } else {
        prep_data <- prep(data,person.id,task.id,occasion,group,max.counts,obs.counts,time,cens)        
      }

    } else {
      flog.info("person.id, and the other column names are necessary.", name="orfrlog")
      return(NULL)
    }   
    
    if (cens == "") { # in case cens == ""
      data$cens <- 0 # all are observed
      cens = "cens"
    }
    
    if (testlet) { # sub task level
      vars <- c(person.id,
                task.id,
                sub.task.id,
                cens)
      data <- data %>% select(all_of(vars)) # select(person.id, task.id, sub.task.id,cens)
      
      col.labels <- c("person.id","task.id","sub.task.id","cens")

      colnames(data) <- col.labels
      
      # get censoring info
      Cens_data <- data.matrix(data %>% 
                          select(person.id, task.id, sub.task.id,cens) %>% 
                          mutate(id.seq = paste0(task.id,sub.task.id)) %>%
                          select(person.id, id.seq, cens) %>% 
                          pivot_wider(names_from = id.seq, values_from = cens) %>% 
                          select(-person.id))
      
      scoring_output <- scoring.sentence.censoring(Count=calib.data$Y, logT10=calib.data$logT10, 
                                 N=calib.data$N,
                                 Passage=calib.data$task.param$task.id,
                                 a=calib.data$task.param$a, b=calib.data$task.param$b,
                                 alpha=calib.data$task.param$alpha, beta=calib.data$task.param$beta,
                                 gamma1=calib.data$hyper.param$gamma1, gamma2=calib.data$hyper.param$gamma2,
                                 sigma=calib.data$hyper.param$sigma, rho=calib.data$hyper.param$rho.theta,
                                 rhoTestlet=calib.data$hyper.param$rho.testlet,
                                 C=Cens_data)
      # scoring_output <- scoring.sentence.censoring(Count=prep_data$data.wide$Y, logT10=prep_data$data.wide$logT10, 
      #                                              N=prep_data$data.wide$N,
      #                                              Passage=calib.data$task.param$task.id,
      #                                              a=calib.data$task.param$a, b=calib.data$task.param$b,
      #                                              alpha=calib.data$task.param$alpha, beta=calib.data$task.param$beta,
      #                                              gamma1=calib.data$hyper.param$gamma1, gamma2=calib.data$hyper.param$gamma2,
      #                                              sigma=calib.data$hyper.param$sigma, rho=calib.data$hyper.param$rho.theta,
      #                                              rhoTestlet=calib.data$hyper.param$rho.testlet,
      #                                              C=Cens_data)
      
      return(invisible(scoring_output))
      
    } else { # task level
      vars <- c(person.id,
                task.id,
                cens)
      data <- data %>% select(all_of(vars)) 
      
      col.labels <- c("person.id","task.id","cens")
      
      colnames(data) <- col.labels
      
      Cens_data <- data.matrix(data %>% 
                          select(person.id, task.id, cens) %>%
                          pivot_wider(names_from = task.id, values_from = cens) %>% 
                          select(-person.id))
      
      scoring_output <- scoring.passage.censoring(Count=prep_data$data.wide$Y, logT10=prep_data$data.wide$logT10, N=prep_data$data.wide$N,
                          a=calib.data$task.param$a, b=calib.data$task.param$b,
                          alpha=calib.data$task.param$alpha, beta=calib.data$task.param$beta,
                          sigma=calib.data$hyper.param$vartau, rho=calib.data$hyper.param$rho,
                          C=Cens_data)
      return(invisible(scoring_output))
    }
  } else {
    if (se == "analytic") {
      if (est != "bayes") { #not bayes
        if (person.id != "") {
          data <- preplong(data,person.id,task.id,occasion,group,max.counts,obs.counts,time)
        }
        # Check MCEM object
        if (class(calib.data)[1] == "fit.model") {
          #      MCEM <- calib.data
          # assign task.data
          task.data <- calib.data$task.param
        } else { # if no MCEM object stop running
          flog.info("Missed fit.model object, end scoring process", name = "orfrlog")
          return(NULL)
        }
        
        if (length(external) != 0) { # external,
          flog.info(paste("Use external task:", paste(external, collapse = ",")))
        }
        
        # Check cases
        if (length(cases) == 0) {
          # print("Cases: ")
          cases <- get.cases(data)
        } else { # check if cases is with "_"
          colnames(cases) <- c("cases")
          if (!grepl("_", cases[1,1], fixed = TRUE)) { # if task.id only
            cases <- cases %>% mutate(across(cases, ~ paste0(.,'_1')))
          } 
        }
        
        # Check if there is a perfect accurate case
        perfect.cases <<- get.perfectcases(data)
        
        if (count(perfect.cases) != 0) {
          flog.info(paste("The perfect accurate case: ", paste(perfect.cases$perfect.cases, collapse = ", ")), name="orfrlog")
        } else {
          flog.info("There is no perfect accurate case.", name="orfrlog")
        }
        
        # Check if there is a zero accurate case
        zero.cases <<- get.zerocases(data)
        
        if (count(zero.cases) != 0) {
          flog.info(paste("The zero accurate case: ", paste(zero.cases$zero.cases, collapse = ", ")), name="orfrlog")
        } else {
          flog.info("There is no zero accurate case.", name="orfrlog")
        }            
        
        result.list <- run.scoring(calib.data, data, task.data, cases, perfect.cases, zero.cases, est, lo = -12, hi = 12, q = 100, kappa = 1, external=external,type=type)
        class(result.list) <- "scoring"
        return(result.list)
        
      } else  { # bayes
        if (person.id == "") { # if without columns' names
          result.list <- bayes.wcpm(
            calib.data = calib.data,
            person.data = data,
            cases = cases,
            external=external,
            type=type,
            parallel=T, #logical, run in parallel? "T" or "F"
            n.chains=NA, # pos. int., number of the chains
            iter=NA,  # pos. int., number of the iterations after the burn-in period
            burn=NA,  # pos. int., number of the burn-in iterations
            thin=1 #pos. int, thinning interval, a.k.a, period of saving samples
          )
        } else {
          result.list <- bayes.wcpm(
            calib.data = calib.data,
            person.data = data,
            person.id = person.id,
            task.id = task.id,
            occasion = occasion,
            group = group,
            max.counts = max.counts,
            obs.counts = obs.counts,
            time = time,
            cases = cases,
            external=external,
            type=type,
            parallel=T, #logical, run in parallel? "T" or "F"
            n.chains=NA, # pos. int., number of the chains
            iter=NA,  # pos. int., number of the iterations after the burn-in period
            burn=NA,  # pos. int., number of the burn-in iterations
            thin=1 #pos. int, thinning interval, a.k.a, period of saving samples
          )
        }
        class(result.list) <- "scoring"
        return(result.list)
      }
    } else if (se == "bootstrap"){ #for bootstrap
      # Check if there is a perfect accurate case
      perfect.cases <<- get.perfectcases(data)
      
      RE_TRY <- failsafe # Define retry, if 0, no retry
      j <- 0 # index for retry time
      i <- 1 # index for case loop
      
      t_size <- nrow(cases)
      
      while (i <= t_size) {
        temp <- tibble()
        flog.info(paste("Boostrap running for case:", cases$cases[i]), name = "orfrlog")
        t_case = data.frame(cases=cases$cases[i])
        tryCatchLog(
          temp <- getBootstrapSE(calib.data, data, case=t_case, perfect.cases, est, kappa=1,bootstrap=bootstrap),
          error=function(e) {
            flog.info(paste("Running error:", e), name = "orfrlog")
          }
        )
        
        if (length(temp) > 2) { #without error
          bootstrap.out <- rbind(bootstrap.out,temp)
          j <- 0 # reset index of retry
          i <- i + 1 # go to next case
        } else { # with error
          if (j == RE_TRY) { # after RE_TRY if still error
            error_temp <- tibble(case_id = cases$cases[i])
            error_case <- rbind(error_case, error_temp)
            i <- i + 1 # go to next case
          } else {
            # let it retry a couple of times
            j <- j + 1
            flog.info(paste("Boostrap try again: time", j), name = "orfrlog")
          }
        }
      }
      result.list <- list(bootstrap.out = bootstrap.out,
                          error_case = error_case)
      class(result.list) <- "bootstrap"
      return(result.list)
    }
  }
}
