#' Estimate the model parameters
#'
#'
#' This is an interface function to estimate the model parameters 
#' based on the task-level (i.e., passage-level in ORF assessment 
#' context) accuracy and speed data by implementing 
#' the Monte Carlo EM algorithm described in Potgieter et al. (2017) or
#' fully Bayesian method described in Kara et al. (2020).
#'
#'
#' @param data A data frame or a data generated by the \code{prep} function. 
#'     If this argument is used with prepared data, 
#'     the next five arguments \code{person.id, task.id, 
#'     max.counts, obs.counts, time} should be skipped.
#' @param person.id Quoted variable name in \code{data} that indicates 
#'     the unique person identifier.
#' @param task.id Quoted variable name in \code{data} that indicates 
#'     the unique task identifier. In the ORF assessment context, it is the
#'     passage identifier.
#' @param sub.task.id Quoted variable name in \code{data} that indicates 
#'     the unique sub task identifier. In the ORF assessment context, it is the
#'     sentence identifier. It is required when testlet is TRUE.
#' @param max.counts Quoted variable name in \code{data} that indicates 
#'     the number of attempts in the task. In the ORF assessment context,
#'     it is the number of words in the passage. 
#' @param obs.counts Quoted variable name in \code{data} that indicates 
#'     the number of successful attempts in each task. In the ORF assessment
#'     context, it is the number of words read correctly for the passage.
#' @param time Quoted variable name in \code{data} that indicates 
#'     the time in seconds took to complete the task. In the ORF context, 
#'     it is the time took to complete reading the passage.
#' @param k.in    Numeric, indicating the number of imputations. 
#'     Default is \code{5}.
#' @param reps.in Numeric, indicating the number of Monte-Carlo iterations. 
#'     Default is \code{2}.
#' @param ests.in An optional list of numeric vectors, indicating 
#'     initial values of the model parameters. If this argument is not given, 
#'     \code{mom} function will be called to generate the initial values.
#' @param est Quoted string, indicating the choice of the estimator. It has
#'     to be one of \code{"mcem", "bayes"}. Default is \code{"mcem"}.
#' @param se Quoted string, indicating the choice of the standard errors. 
#'     It has to be one of \code{"none", "analytic", "bootstrap"}. 
#'     Default is \code{"none"}.
#' @param verbose Boolean. If \code{TRUE}, the summary will be output.
#'     Default is \code{FALSE}.
#' @param testlet Boolean. If \code{TRUE}, the fit.model.testlet will be run.
#'     Default is \code{FALSE}.
#'
#' @details
#' Additional details...
#' 
#' @note
#' More & more additional note...
#' 
#' @seealso \code{\link{scoring}} for scoring.
#'
#' @references 
#'   Potgieter, N., Kamata, A., & Kara, Y. (2017). An EM algorithm for 
#'   estimating an oral reading speed and accuracy model. Manuscript submitted 
#'   for publication.  
#'   
#'   Kara, Y., Kamata, A., Potgieter, C., & Nese, J. F. (2020). Estimating 
#'   model-based oral reading fluency: A bayesian approach with a 
#'   binomial-lognormal joint latent model. 
#'   Educational and Psychological Measurement, 1–25.
#'   
#' @examples
#' # example code
#' MCEM_run <- fit.model(data = passage2,
#'                       person.id = "id.student",
#'                       task.id = "id.passage",
#'                       max.counts = "numwords.pass",
#'                       obs.counts = "wrc",
#'                       time = "sec",
#'                       k.in = 5,
#'                       reps.in = 50,
#'                       est = "mcem")
#' 
#' @return MCEM list, bayes list
#' @export
fit.model <- function(data=NA, person.id="",task.id="",sub.task.id="",max.counts="",obs.counts="",time="", k.in=5,reps.in=2,ests.in=NA,
                      est="mcem",se="none",verbose=FALSE, testlet=FALSE) {
  # loading logger
  log.initiating()

  if (person.id != "") {
    if (testlet) { # for sub task level 

      # call fit.model.testlet
      output <- fit.model.testlet(data,person.id,sub.task.id,obs.counts,time,task.id,max.counts)
      if (verbose == TRUE) {
        summary.fit.model.testlet(output)
      }
      return(invisible(output))
    } else { # task level 
      #create wide data
      if (est != "bayes") {
        data <- prepwide(data,person.id,task.id,max.counts,obs.counts,time)       
      }
    }
  } else { # prepared data
    if (testlet) { # for sub task level 
      output <- fit.model.testlet(data$data.long,person.id="person.id",sub.task.id="sub.task.id",obs.counts="obs.counts",time="time",task.id="task.id",max.counts="max.counts")
      if (verbose == TRUE) {
        summary.fit.model.testlet(output)
      }
      return(invisible(output))
    } else {
      data <- data$data.wide      
    }
  }
  

  if (est == "mcem") {
    flog.info("Begin mcem process", name = "orfrlog")
    
    if (se == "none") {

      MCEMests <- run.mcem(data$Y,data$logT10,data$N,data$I,k.in,reps.in,ests.in,verbose=verbose)

      task.param <-  tibble(
        a = MCEMests$a,
        b = MCEMests$b,
        alpha = MCEMests$alpha,
        beta = MCEMests$beta,
        task.id = as.numeric(colnames(data$Y)),
        max.counts = data$N)
      hyper.param <- tibble(vartau = MCEMests$vartau,
                            rho = MCEMests$rho)
      MCEM.ests <- list(task.param = task.param,
                        hyper.param = hyper.param)
    } else {
      # test
      # if (is.na(ests.in)) {
      #   ests.in <- mom(data$Y, data$logT10, data$N, data$I)
      # }

      MCEMests <- run.mcem(data$Y, data$logT10, data$N, data$I,
                           k.in=k.in, reps.in=reps.in,ests.in=ests.in)

      MCEMout <- c(MCEMests$a, MCEMests$b, MCEMests$alpha,
                   MCEMests$beta, MCEMests$vartau, MCEMests$rho)
      if (se == "analytic") {
        CV.analytic <- numerical.cov(data$Y, data$logT10, data$N, data$I,
                                     MCEMout,h.val=1e-10, M=100)
      } else { # bootstrap
        # CV.analytic <- boot.cov(data$Y, data$logT10, data$N, data$I,
        #                         k.in=8, reps.in=3, B=10)
        # an alternative function
        CV.analytic <- bootmodel.cov(data$Y, data$logT10, data$N, data$I,
                                     MCEMout,k.in=k.in, reps.in=reps.in,B=10)

      }
      SE.analytic <- sqrt(diag(CV.analytic))

      task.param <-  tibble(
        a = MCEMests$a,
        b = MCEMests$b,
        alpha = MCEMests$alpha,
        beta = MCEMests$beta,
        se.a = SE.analytic[1:length(MCEMests$a)],
        se.b = SE.analytic[(length(MCEMests$a)+1):(length(MCEMests$a)+length(MCEMests$b))],
        se.alpha = SE.analytic[(length(MCEMests$a)+length(MCEMests$b)+1):(length(MCEMests$a)+length(MCEMests$b)+length(MCEMests$alpha))],
        se.beta = SE.analytic[(length(MCEMests$a)+length(MCEMests$b)+length(MCEMests$alpha)+1):(length(MCEMests$a)+length(MCEMests$b)+length(MCEMests$alpha)+length(MCEMests$beta))],
        task.id = as.numeric(colnames(data$Y)),
        max.counts = data$N)
      hyper.param <- tibble(vartau = MCEMests$vartau,
                            rho = MCEMests$rho,
                            se.vartau = SE.analytic[(length(MCEMests$a)+length(MCEMests$b)+length(MCEMests$alpha)+length(MCEMests$beta)+1)],
                            se.rho = SE.analytic[(length(MCEMests$a)+length(MCEMests$b)+length(MCEMests$alpha)+length(MCEMests$beta)+2)])
      MCEM.ests <- list(task.param = task.param,
                        hyper.param = hyper.param)
    }


    # check if shows the summary
    if (verbose == TRUE) {
      summary.fit.model(MCEM.ests)
    }
    class(MCEM.ests) <- "fit.model" # define class
    flog.info("End mcem process", name = "orfrlog")
    return(invisible(MCEM.ests))


  } else { # for bayes, mcem parameters are necessary
    flog.info("Begin bayes process", name = "orfrlog")
    bayes.ests <- bayes(data,
                       person.id,
                       task.id,
                       max.counts,
                       obs.counts,
                       time,
                       parallel=T, #logical, run in parallel? "T" or "F"
                       n.chains=NA, # pos. int., number of the chains
                       thin=1, #pos. int, thinning interval, a.k.a, period of saving samples
                       iter=NA,  # pos. int., number of the iterations after the burn-in period
                       burn=NA  # pos. int., number of the burn-in iterations)
    )
    # check if shows the summary
    if (verbose == TRUE) {
      summary.fit.model(bayes.ests)
    }

    class(bayes.ests) <- "fit.model" # define class
    flog.info("End bayes process", name = "orfrlog")
    return(invisible(bayes.ests))
  }
}

#' Estimate factor scores with task-level model
#'
#' This is an interface function to estimated factor scores based on the 
#' task-level (i.e., passage-level in ORF assessment context) accuracy 
#' and speed data. It implements likelihood-based approaches (MLE, MAP,
#' or EAP) described in Qiao et al. (under review) or fully Bayesian 
#' method described in Kara et al. (2020).
#' 
#'
#' @param calib.data A class object. Output from calibration phase 
#'     by \code{\link{fit.model}} function
#' @param data A data frame. It is necessary when with 
#'      the next five arguments \code{person.id, task.id, 
#'     max. counts, obs. counts, time}.
#' @param person.id Quoted variable name in \code{data} that 
#'     indicates the unique individual identifier.
#' @param task.id Quoted variable name in \code{data} that 
#'     represents the unique task identifier. In the ORF assessment
#'     context, it is the passage identifier.
#' @param sub.task.id Quoted variable name in \code{data} that indicates 
#'     the unique sub task identifier. In the ORF assessment context, it is the
#'     sentence identifier. It is required when testlet is TRUE.
#' @param max.counts Quoted variable name in \code{data} that 
#'     represents the number of attempts in the task. In the ORF assessment
#'     context, it is the number of words in the passage.
#' @param occasion The column name in the data that represents the unique occasion.
#' @param group The column name in the data that represents the unique group.
#' @param obs.counts The column name in the data that represents the words read correctly for each case.
#' @param time The column name in the data that represents the time, in seconds, for each case.
#' @param cens The column name in the data that represents the censoring indicators 
#'      whether a specific task or sub task was censored (1) or fully observed (0).
#'      This column is necessary when censoring argument is TRUE.
#' @param cases A vector of individual id for which scoring is desired. If no information is 
#'      is specified, it will estimate scores for all cases in the \code{data}.
#' @param est Quoted string, indicating the choice of the estimator. It has to be one of 
#'      code/{"mle", "map", "eap", "bayes"}. Default is \code{"map"}.
#' @param se Quoted string, indication the choice of the standard errors. It has to be one of
#'      code/{"analytic", "bootstrap"}. Default is \code{"analytic"}.
#' @param failsafe Numeric, indicating the number of retries for bootstrap, which can be set between
#'      0 and 50. Default is 0.
#' @param bootstrp Numeric, indicating the number of bootstrap iterations. Default is 100.
#' @param external An optional vector of task ID's in strings. If \code{NULL} (default), 
#'      the wcpm scores are derived with the tasks the individuals were assigned to. 
#'      If not \code{NULL}, wcpm scores are derived with the tasks provided in the vector, rather
#'      than the tasks the individuals were assigned.
#' @param type Quoted string, indication of the choice of output. If \code{"general"} (default),
#'      wcpm scores are not reported. If \code{"orf"}, wcpm scores will be reported.
#' @param censoring Boolean. If \code{TRUE}, interface will call task or sub task censoring.
#'      Default is \code{FALSE}.
#' @param testlet Boolean. If \code{TRUE}, runs with sub task level, otherwise, with task level.
#'      This argument is necessary when censoring is TRUE. Default is \code{FALSE}.
#'
#' @details
#' Additional details...
#' 
#' @note
#' More additional note...
#' 
#' @seealso \code{\link{fit.model}} for model parameter estimation.
#'
#' @references 
#'   Qiao, X, Potgieter, N., & Kamata, A. (2023). Likelihood Estimation of 
#'   Model-based Oral Reading Fluency. Manuscript submitted 
#'   for publication.  
#'   
#'   Kara, Y., Kamata, A., Potgieter, C., & Nese, J. F. (2020). Estimating 
#'   model-based oral reading fluency: A bayesian approach with a 
#'   binomial-lognormal joint latent model. 
#'   Educational and Psychological Measurement, 1–25.
#'   
#' @examples
#' # example code
#' WCPM_all <- scoring(calib.data=MCEM_run, 
#'                    data = passage2,
#'                    person.id = "id.student",
#'                    occasion = "occasion",
#'                    group = "grade",
#'                    task.id = "id.passage",
#'                    max.counts = "numwords.pass",
#'                    obs.counts = "wrc",
#'                    time = "sec",
#'                    est = "map", 
#'                    se = "analytic",
#'                    type="general")
#' 
#' @return scoring list or Bootstrap dataset or censoring list
#' @export
scoring <- function(calib.data=NA, data=NA, person.id="", task.id="", sub.task.id="", occasion="", group="", max.counts="", obs.counts="", time="", cens="", cases=NULL,
                    est="map", se="analytic",failsafe=0, bootstrap=100, external=NULL, type="general", censoring=FALSE, testlet=FALSE) {
  # loading logger
  log.initiating()
  
  bootstrap.out <- tibble()
  error_case <- tibble()
  prep_data <- NULL
  
  if (testlet == TRUE) {
    censoring <- TRUE
  }
  
  # with censoring
  if (censoring) {
    
    #Check if scoring will be done for specific cases of data. 
    if(is.character(cases)){
      data <- data
    }else{
      colnames(cases) <- "cases"
      id_col <- which(colnames(data)==person.id)
      if (occasion == ""){ 
        id_sel <- unlist(data[,id_col], use.names = F) %in% cases$cases
        data <- data[id_sel,]
      }else {
        occ_col <- which(colnames(data)==occasion)
        id_new <- paste(unlist(data[,id_col]), unlist(data[,occ_col]), sep = "_")
        id_sel <- id_new %in% cases$cases
        data <- data[id_sel,]
      }
    }
    
    if (person.id != "") {
      if (testlet) { # should with sub.task.id
        prep_data <- prep(data=data,person.id=person.id,task.id=task.id,sub.task.id=sub.task.id,occasion=occasion,group=group,max.counts=max.counts,obs.counts=obs.counts,time=time,cens=cens,sentence_level = TRUE)
      } else {
        prep_data <- prep(data=data,person.id=person.id,task.id=task.id,occasion=occasion,group=group,max.counts=max.counts,obs.counts=obs.counts,time=time,cens=cens)        
      }
      
      if (cens == "") { # in case cens == ""
        data$cens <- 0 # all are observed
        cens <- "cens"
      }
    } else { # if already with prep_data
      # flog.info("person.id, and the other column names are necessary.", name="orfrlog")
      # return(NULL)
      # set items from prepared data
      tryCatch (
        expr = {
          prep_data <- data
          data <- data$data.long
          
          person.id <- "person.id"
          task.id <- "task.id"
          
          if (testlet) {
            sub.task.id <- "sub.task.id"      
            occasion <- "occasion"
            group <- "group"
            max.counts <- "max.counts"
            obs.counts <- "obs.counts"
            time <- "time"
          } else {
            occasion <- "occasion"
            group <- "group"
            max.counts <- "max.counts"
            obs.counts <- "obs.counts"
            time <- "time"            
          }

          
          if ("cens" %in% c(colnames(data))) {
            cens <- "cens"           
          } else {
            data$cens <- 0 # all are observed
            cens <- "cens"
          }

        },
        error = function(w) {
          flog.info("Please make sure your prepared data is correct!", name = "orfrlog")
          flog.info(w, name = "orfrlog")
        }
      )
    }   
    

    if (testlet) { # sub task level
      # save data
      preped_data <- prep_data$data.long
      
      # need to keep the order of person.id as group_by and summarize will automatically order the id
      original_order <- preped_data %>%
        distinct(person.id) %>%
        mutate(order = row_number())
      
      temp_summary <- preped_data %>%
        group_by(person.id, task.id) %>%
        summarise(max.counts.sum = sum(max.counts, na.rm = TRUE), 
                  obs.counts.sum = sum(obs.counts, na.rm = TRUE), .groups = "drop") %>%
        group_by(person.id) %>%
        summarise(
          task.n = n(), 
          max.counts.total = sum(max.counts.sum),
          obs.counts.total = sum(obs.counts.sum),
          .groups = "drop"
        )
      
      subtask_summary <- preped_data %>%
        group_by(person.id) %>%
        summarise(sub.task.n = n(), 
                  secs.obs = sum(time, na.rm = TRUE), 
                  occasion = n_distinct(occasion), 
                  group = n_distinct(group), .groups = "drop")
      
      temp_summary <- temp_summary %>%
        left_join(subtask_summary, by = "person.id") %>% mutate(wcpm.obs = obs.counts.total/secs.obs*60)

      # restore the order of person.id 
      temp_summary <- temp_summary %>%
        left_join(original_order, by = "person.id") %>%
        arrange(order) %>%
        select(-order)
      
      vars <- c(person.id,
                task.id,
                sub.task.id,
                cens)
      data <- data %>% select(all_of(vars)) # select(person.id, task.id, sub.task.id,cens)
      
      col.labels <- c("person.id","task.id","sub.task.id","cens")

      colnames(data) <- col.labels
      
      # get censoring info
      Cens_data <- data.matrix(data %>% 
                          select(person.id, task.id, sub.task.id,cens) %>% 
                          mutate(id.seq = paste0(task.id,sub.task.id)) %>%
                          select(person.id, id.seq, cens) %>% 
                          pivot_wider(names_from = id.seq, values_from = cens) %>% 
                          select(-person.id))
      
      #Filter the parameters in the calib data for sentences read
      param_read <- data %>%
        select(task.id, sub.task.id) %>%
        distinct() %>%
        mutate(sub.task.id=as.numeric(paste(task.id, sub.task.id, sep = ""))) %>%
        left_join(calib.data$task.param)
      
      a_read <- param_read$a
      b_read <- param_read$b
      alpha_read <- param_read$alpha
      beta_read <- param_read$beta
      passage_read <- param_read$task.id
      N_read <- prep_data$data.wide$N.vec %>% as.vector() %>% unlist()
      
      #Conditional for external scoring.
      if((length(external) == 0)){ #if no external, wcpm will be estimated from the passages & sentences read! Using the same strategy as in bayes.wcpm function. 
        a_score <- a_read
        b_score <- b_read
        alpha_score <- alpha_read 
        beta_score <- beta_read
        N_score <- N_read
        passage_score <- passage_read
      }else{
        #pull the below from the "external" vector supplied!
        #Will be edited later, after we see what is the rule for the task and sub.task ID scheme?
        param_score <- calib.data$task.param %>%
          mutate(Nwords=calib.data$N) %>%
          filter(sub.task.id %in% external)
          
        a_score <- param_score$a
        b_score <- param_score$b
        alpha_score <- param_score$alpha
        beta_score <- param_score$beta
        N_score <- param_score$Nwords
        passage_score <- param_score$task.id
      }
      
     # scoring_output <- scoring.sentence.censoring(Count=calib.data$Y, logT10=calib.data$logT10, 
     #                             N=calib.data$N,
     #                             Passage=calib.data$task.param$task.id,
     #                            a=calib.data$task.param$a, b=calib.data$task.param$b,
     #                             alpha=calib.data$task.param$alpha, beta=calib.data$task.param$beta,
     #                             gamma1=calib.data$hyper.param$gamma1, gamma2=calib.data$hyper.param$gamma2,
     #                             sigma=calib.data$hyper.param$sigma, rho=calib.data$hyper.param$rho.theta,
     #                            rhoTestlet=calib.data$hyper.param$rho.testlet,
     #                             C=Cens_data)
     
       scoring_output <- scoring.sentence.censoring(Count=prep_data$data.wide$Y, 
                                                    logT10=prep_data$data.wide$logT10, 
                                                    N=N_read,
                                                    N_score=N_score,
                                                    Passage=passage_read,
                                                    Passage_score=passage_score,
                                                    a=a_read, 
                                                    b=b_read,
                                                    alpha=alpha_read, 
                                                    beta=beta_read,
                                                    a_score=a_score, 
                                                    b_score=b_score,
                                                    alpha_score=alpha_score, 
                                                    beta_score=beta_score,
                                                    gamma1=calib.data$hyper.param$gamma1, 
                                                    gamma2=calib.data$hyper.param$gamma2,
                                                    sigma=calib.data$hyper.param$sigma, 
                                                    rho=calib.data$hyper.param$rho.theta,
                                                    rhoTestlet=calib.data$hyper.param$rho.testlet,
                                                    C=Cens_data, 
                                                    type=type)
      
      
      
       out <- tibble(person.id=temp_summary$person.id, occasion=temp_summary$occasion, group=temp_summary$group,
                     task.n=temp_summary$task.n,
                     sub.task.n=temp_summary$sub.task.n, max.counts.total=temp_summary$max.counts.total,
                     obs.counts.total=temp_summary$obs.counts.total, 
                     secs.obs=temp_summary$secs.obs, wcpm.obs=temp_summary$wcpm.obs,
                     tau.bayes=scoring_output$theta_spd_est,
                     theta.bayes=scoring_output$theta_acc_est,
                     se.tau.bayes=scoring_output$theta_spd_sd,
                     se.theta.bayes=scoring_output$theta_acc_sd,
                     count.bayes = scoring_output$count_est,
                     se.count.bayes = scoring_output$count_sd,
                     secs.bayes = scoring_output$time_est,
                     se.secs.bayes = scoring_output$time_sd,
                     wcpm.bayes = scoring_output$wcpm_est,
                     se.wcpm.bayes = scoring_output$wcpm_sd)
       
       class(out) <- "scoring.censoring"
       return(invisible(out))
      
    } else { # task level

    original_order <- prep_data$data.long %>% #data
        distinct(person.id) %>%
        mutate(order = row_number())
      
      temp_summary <- prep_data$data.long %>%
        group_by(person.id) %>%
        summarise(
          task.n = n_distinct(task.id), # Number of unique tasks
          max.counts.total = sum(max.counts),
          obs.counts.total = sum(obs.counts),
          .groups = "drop"
        )
      
      subtask_summary <- prep_data$data.long %>%
        group_by(person.id) %>%
        summarise(#sub.task.n = n(), 
                  secs.obs = sum(time, na.rm = TRUE), 
                  occasion = n_distinct(occasion), 
                  group = n_distinct(group), .groups = "drop")
      
      temp_summary <- temp_summary %>%
        left_join(subtask_summary, by = "person.id") %>% mutate(wcpm.obs = obs.counts.total/secs.obs*60)
      
      temp_summary <- temp_summary %>%
        left_join(original_order, by = "person.id") %>%
        arrange(order) %>%
        select(-order)
      
      vars <- c(person.id,
                task.id,
                cens)
      data <- data %>% select(all_of(vars)) 
      
      col.labels <- c("person.id","task.id","cens")
      
      colnames(data) <- col.labels
      
      Cens_data <- data.matrix(data %>% 
                          select(person.id, task.id, cens) %>%
                          pivot_wider(names_from = task.id, values_from = cens) %>% 
                          select(-person.id))
      
      
      #Filter the parameters in the calib data for passages read
      param_read <- data %>%
        select(task.id) %>%
        distinct() %>%
        mutate(task.id=as.numeric(task.id)) %>%
        left_join(calib.data$task.param)
      
      a_read <- param_read$a
      b_read <- param_read$b
      alpha_read <- param_read$alpha
      beta_read <- param_read$beta
      passage_read <- param_read$task.id
      N_read <- param_read$max.counts
      
      #Conditional for external scoring.
      if((length(external) == 0)){ #if no external, wcpm will be estimated from the passages & sentences read! Using the same strategy as in bayes.wcpm function. 
        a_score <- a_read
        b_score <- b_read
        alpha_score <- alpha_read 
        beta_score <- beta_read
        N_score <- N_read
        passage_score <- passage_read
      }else{
        #pull the below from the "external" vector supplied!
        param_score <- calib.data$task.param %>%
          rename(Nwords=max.counts) %>%
          filter(task.id %in% external)
        
        a_score <- param_score$a
        b_score <- param_score$b
        alpha_score <- param_score$alpha
        beta_score <- param_score$beta
        N_score <- param_score$Nwords
        passage_score <- param_score$task.id
      }
      
      scoring_output <- scoring.passage.censoring(Count=prep_data$data.wide$Y, 
                                                  logT10=prep_data$data.wide$logT10, 
                                                  N=N_read,
                                                  N_score=N_score, 
                                                  a=a_read,
                                                  b=b_read, 
                                                  alpha=alpha_read,  
                                                  beta=beta_read,
                                                  a_score=a_score, 
                                                  b_score=b_score,
                                                  alpha_score=alpha_score, 
                                                  beta_score=beta_score,
                                                  sigma=calib.data$hyper.param$vartau, 
                                                  rho=calib.data$hyper.param$rho,
                                                  C=Cens_data, 
                                                  type=type)

      out <- tibble(person.id=temp_summary$person.id, occasion=temp_summary$occasion, group=temp_summary$group,
                    task.n=temp_summary$task.n,
                    max.counts.total=temp_summary$max.counts.total,
                    obs.counts.total=temp_summary$obs.counts.total, 
                    secs.obs=temp_summary$secs.obs, wcpm.obs=temp_summary$wcpm.obs,
                    tau.bayes=scoring_output$theta_spd_est,
                    theta.bayes=scoring_output$theta_acc_est,
                    se.tau.bayes=scoring_output$theta_spd_sd,
                    se.theta.bayes=scoring_output$theta_acc_sd,
                    count.bayes = scoring_output$count_est,
                    se.count.bayes = scoring_output$count_sd,
                    secs.bayes = scoring_output$time_est,
                    se.secs.bayes = scoring_output$time_sd,
                    wcpm.bayes = scoring_output$wcpm_est,
                    se.wcpm.bayes = scoring_output$wcpm_sd)
      
      class(out) <- "scoring.censoring"
      return(invisible(out))
    }
  } else { # without censoring ---------------------------------------------------------------------------------------------
    if (se == "analytic") {
      if (est != "bayes") { #not bayes
        if (person.id != "") {
          data <- preplong(data,person.id,task.id,occasion,group,max.counts,obs.counts,time)
        }
        # Check MCEM object
        if (class(calib.data)[1] == "fit.model") {
          #      MCEM <- calib.data
          # assign task.data
          task.data <- calib.data$task.param
        } else { # if no MCEM object stop running
          flog.info("Missed fit.model object, end scoring process", name = "orfrlog")
          return(NULL)
        }
        
        if (length(external) != 0) { # external,
          flog.info(paste("Use external task:", paste(external, collapse = ",")))
        }
        
        # Check cases
        if (length(cases) == 0) {
          # print("Cases: ")
          cases <- get.cases(data)
        } else { # check if cases is with "_"
          colnames(cases) <- c("cases")
          if (!grepl("_", cases[1,1], fixed = TRUE)) { # if task.id only
            cases <- cases %>% mutate(across(cases, ~ paste0(.,'_1')))
          } 
        }
        
        # Check if there is a perfect accurate case
        perfect.cases <<- get.perfectcases(data)
        
        if (count(perfect.cases) != 0) {
          flog.info(paste("The perfect accurate case: ", paste(perfect.cases$perfect.cases, collapse = ", ")), name="orfrlog")
        } else {
          flog.info("There is no perfect accurate case.", name="orfrlog")
        }
        
        # Check if there is a zero accurate case
        zero.cases <<- get.zerocases(data)
        
        if (count(zero.cases) != 0) {
          flog.info(paste("The zero accurate case: ", paste(zero.cases$zero.cases, collapse = ", ")), name="orfrlog")
        } else {
          flog.info("There is no zero accurate case.", name="orfrlog")
        }            
        
        result.list <- run.scoring(calib.data, data, task.data, cases, perfect.cases, zero.cases, est, lo = -12, hi = 12, q = 100, kappa = 1, external=external,type=type)
        class(result.list) <- "scoring"
        return(result.list)
        
      } else  { # bayes
        if (person.id == "") { # if without columns' names
          result.list <- bayes.wcpm(
            calib.data = calib.data,
            person.data = data,
            cases = cases,
            external=external,
            type=type,
            parallel=T, #logical, run in parallel? "T" or "F"
            n.chains=NA, # pos. int., number of the chains
            iter=NA,  # pos. int., number of the iterations after the burn-in period
            burn=NA,  # pos. int., number of the burn-in iterations
            thin=1 #pos. int, thinning interval, a.k.a, period of saving samples
          )
        } else {
          result.list <- bayes.wcpm(
            calib.data = calib.data,
            person.data = data,
            person.id = person.id,
            task.id = task.id,
            occasion = occasion,
            group = group,
            max.counts = max.counts,
            obs.counts = obs.counts,
            time = time,
            cases = cases,
            external=external,
            type=type,
            parallel=T, #logical, run in parallel? "T" or "F"
            n.chains=NA, # pos. int., number of the chains
            iter=NA,  # pos. int., number of the iterations after the burn-in period
            burn=NA,  # pos. int., number of the burn-in iterations
            thin=1 #pos. int, thinning interval, a.k.a, period of saving samples
          )
        }
        class(result.list) <- "scoring"
        return(result.list)
      }
    } else if (se == "bootstrap"){ #for bootstrap
      # Check if there is a perfect accurate case
      perfect.cases <<- get.perfectcases(data)
      
      RE_TRY <- failsafe # Define retry, if 0, no retry
      j <- 0 # index for retry time
      i <- 1 # index for case loop
      
      t_size <- nrow(cases)
      
      while (i <= t_size) {
        temp <- tibble()
        flog.info(paste("Boostrap running for case:", cases$cases[i]), name = "orfrlog")
        t_case = data.frame(cases=cases$cases[i])
        tryCatchLog(
          temp <- getBootstrapSE(calib.data, data, case=t_case, perfect.cases, est, kappa=1,bootstrap=bootstrap),
          error=function(e) {
            flog.info(paste("Running error:", e), name = "orfrlog")
          }
        )
        
        if (length(temp) > 2) { #without error
          bootstrap.out <- rbind(bootstrap.out,temp)
          j <- 0 # reset index of retry
          i <- i + 1 # go to next case
        } else { # with error
          if (j == RE_TRY) { # after RE_TRY if still error
            error_temp <- tibble(case_id = cases$cases[i])
            error_case <- rbind(error_case, error_temp)
            i <- i + 1 # go to next case
          } else {
            # let it retry a couple of times
            j <- j + 1
            flog.info(paste("Boostrap try again: time", j), name = "orfrlog")
          }
        }
      }
      result.list <- list(bootstrap.out = bootstrap.out,
                          error_case = error_case)
      class(result.list) <- "bootstrap"
      return(result.list)
    }
  }
}
