% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Interface.R
\name{scoring}
\alias{scoring}
\title{Estimate factor scores with task-level model}
\usage{
scoring(
  calib.data = NA,
  person.data = NA,
  person.id = "",
  task.id = "",
  occasion = "",
  group = "",
  max.counts = "",
  obs.counts = "",
  time = "",
  cases = NULL,
  est = "map",
  se = "analytic",
  failsafe = 0,
  bootstrap = 100,
  external = NULL,
  type = "general"
)
}
\arguments{
\item{calib.data}{A class object. Output from calibration phase 
by \code{\link{fit.model}} function}

\item{person.data}{A data frame. A long-format response data object.}

\item{person.id}{Quoted variable name in \code{person.data} that 
indicates the unique individual identifier.}

\item{task.id}{Quoted variable name in \code{person.data} that 
represents the unique task identifier. In the ORF assessment
context, it is the passage identifier.}

\item{occasion}{The column name in the data that represents the unique occasion.}

\item{group}{The column name in the data that represents the unique group.}

\item{max.counts}{Quoted variable name in \code{person.data} that 
represents the number of attempts in the task. In the ORF assessment
context, it is the number of words in the passage.}

\item{obs.counts}{The column name in the data that represents the words read correctly for each case.}

\item{time}{The column name in the data that represents the time, in seconds, for each case.}

\item{cases}{A vector of individual id for which scoring is desired. If no information is 
is specified, it will estimate scores for all cases in the \code{person.data}.}

\item{est}{Quoted string, indicating the choice of the estimator. It has to be one of 
code/{"mle", "map", "eap", "bayes"}. Default is \code{"map"}.}

\item{se}{Quoted string, indication the choice of the standard errors. It has to be one of
code/{"analytic", "bootstrap"}. Default is \code{"analytic"}.}

\item{failsafe}{Numeric, indicating the number of retries for bootstrap, which can be set between
0 and 50. Default is 0.}

\item{external}{An optional vector of task ID's in strings. If \code{NULL} (default), 
the wcpm scores are derived with the tasks the individuals were assigned to. 
If not \code{NULL}, wcpm scores are derived with the tasks provided in the vector, rather
than the tasks the individuals were assigned.}

\item{type}{Quoted string, indication of the choice of output. If \code{"general"} (default),
wcpm scores are not reported. If \code{"orf"}, wcpm scores will be reported.}

\item{bootstrp}{Numeric, indicating the number of bootstrap iterations. Default is 100.}
}
\value{
scoring list or Bootstrap dataset
}
\description{
This is an interface function to estimated factor scores based on the 
task-level (i.e., passage-level in ORF assessment context) accuracy 
and speed data. It implements likelihood-based approaches (MLE, MAP,
or EAP) described in Qiao et al. (under review) or fully Bayesian 
method described in Kara et al. (2020).
}
\details{
Additional details...
}
\note{
More additional note...
}
\examples{
# example code
WCPM_all <- scoring(calib.data=MCEM_run, 
                   person.data = passage2,
                   person.id = "id.student",
                   occasion = "occasion",
                   group = "grade",
                   task.id = "id.passage",
                   max.counts = "numwords.pass",
                   obs.counts = "wrc",
                   time = "sec",
                   est = "map", 
                   se = "analytic",
                   type="general")

}
\references{
Qiao, X, Potgieter, N., & Kamata, A. (2023). Likelihood Estimation of 
  Model-based Oral Reading Fluency. Manuscript submitted 
  for publication.  
  
  Kara, Y., Kamata, A., Potgieter, C., & Nese, J. F. (2020). Estimating 
  model-based oral reading fluency: A bayesian approach with a 
  binomial-lognormal joint latent model. 
  Educational and Psychological Measurement, 1â€“25.
}
\seealso{
\code{\link{fit.model}} for model parameter estimation.
}
